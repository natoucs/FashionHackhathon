{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Start Tuesday 25th Sept 15:00.\n",
    "\n",
    "Supervised learning: using description or attributes labels to build it.\n",
    "Unsupervised learning: Using the image and forgetting the attributes.\n",
    "\n",
    "Ideas?\n",
    "- Do something with AI but demonstrating your business awareness - ie. the usefulness of what you implement for the company and customers.\n",
    "- Recommend similar products using only visual similiraity (PCA with misclassified objects assumed similar)\n",
    "- Recommend products using label similarity extracted from the image.\n",
    "- Data building: using a GAN to generate a product image from attribute+description\n",
    "- Data building: Generating attributes from image+description (generating description too hard)\n",
    "- Data building: Generating attributes from image only (simpler to start)\n",
    "- Data enriching: Generate more attributes for an image using the other images\n",
    "- Read on what ASOS does and propose it to Farfetch (if more time)\n",
    "- Average all non white pixels of photo to decide on product's color.\n",
    "- Train network to decide wether cloth is man, woman, unisex. Maybe simple SVM or KNN.\n",
    "- Maybe a Random Forest is good to decide on sub-attributes like short/long sleeve once t-shirt node is reached.\n",
    "- Data augmentation if training samples are too small for a class. But relevant ? As every product photographed in perfect conditions.\n",
    "\n",
    "Be careful:\n",
    "- Training time, you only have your CPU, no AWS or GPU.\n",
    "\n",
    "Attitude: \n",
    "- Start by implementing with techniques you know, if you have more time, venture off trying new algorithm from the internet.\n",
    "- This is a 48h Hackathon, don't stop.\n",
    "- Don't use all the data provided, try doing a lot with only a small part and then expand your model using more data types.\n",
    "\n",
    "Random comments:\n",
    "- Product photos are formatted perfectly. No processing needed. So less of a computer vision task, more of an ML one.\n",
    "- Similar to Fashion MNIST challenge so get inspired of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0 - Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Use numpy array as a read-only table matrix\n",
    "# Use lists to do processing (find, sort..)\n",
    "location = 'attributes.csv'\n",
    "tmp = np.genfromtxt(location, delimiter=',', dtype=np.string_) #load csv\n",
    "attributes = tmp[1:,:] #remove headers\n",
    "attributes_headers = tmp[0]\n",
    "attributesIds = attributes[:,0].tolist() \n",
    "attributesNames = attributes[:,1].tolist() \n",
    "print(attributes.shape)\n",
    "print(attributes_headers)\n",
    "print(attributes[545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 'products.csv'\n",
    "tmp = np.genfromtxt(location, delimiter=',', dtype=np.string_, comments=None, usecols=np.arange(0,12)) #added 2 conditions for import to work \n",
    "products = tmp[1:,:] \n",
    "products_headers = tmp[0]\n",
    "productsIds = products[:,0].tolist()\n",
    "print(products.shape)\n",
    "print(products_headers)\n",
    "print(products[545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "imageFullNames = os.listdir('images')\n",
    "imageIds = [a.split(\"_\", 1)[0] for a in imageFullNames] #remove file name after ProductId\n",
    "print(imageFullNames[56])\n",
    "print(imageIds[56])\n",
    "print(len(imageFullNames))\n",
    "print(len(imageIds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Get comfortable with manipulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(any(count > 3 for count in Counter(attributesIds).itervalues()) ) \n",
    "print(any(count > 4 for count in Counter(attributesIds).itervalues()) ) \n",
    "print(any(count > 1 for count in Counter(productsIds).itervalues()) ) \n",
    "print(any(count > 1 for count in Counter(imageIds).itervalues()) )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "STATS\n",
    "# Up to 4 same ProductId in attributes (13455 attri across 7362 ProductIds) # 5269 products missing any attributes\n",
    "# 1 description per ProductId (12631 descri) # 12631 unique ProductIds ALL with a descri (exhaustive)\n",
    "# 1 image per ProductId (12436 img) # 195 products missing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "# Functions to manipulate the data - Better to pre-store everything with a dictionary - Complexity/Computation tradeoff (to do later)\n",
    "# Get image file name from a ProductId ->  'images/' + imageFullNames[ imageIds.index( myProductId ) ] \n",
    "# Get attributes from a ProductId -> attributes[ attributesIds.index( myProductId ) ] \n",
    "# Get description from a ProductId - > products[ productsIds.index( myProductId ) ] \n",
    "myProductId = attributesIds[587]\n",
    "print( attributes[ attributesIds.index( myProductId ) ] )\n",
    "print( products[ productsIds.index( myProductId ) ] )\n",
    "Image( 'images/' + imageFullNames[ imageIds.index( myProductId ) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Generate attributes for products missing some (supervised learning)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ideas?\n",
    "- Some attributes are complimentary, some opposite, how to enforce this in the model \n",
    "- Try kmeans clustering on pixels of product image\n",
    "- Try PCA on objects\n",
    "- Could embed each attribute as a point of a certain dimension (autoencoder) & measure Euclidean distance to this point\n",
    "- Could use probabilistic output (normalised) of a CNN to decide on attributes to give to an image\n",
    "- Hierarchy present with AttributeName and AttributeValueName. Start on AttributeName, hierarchy thinking later.\n",
    "\n",
    "ToDo:\n",
    "- Generate list of ProductId with attributes and with an image -> divide in train/test set\n",
    "- Generate list of ProductId with no attributes and with an image -> apply algo on it\n",
    "- Tune the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - Build the train, test, application datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributesNamesUnique, counts = np.unique(attributesNames, return_counts=True) #change to 2 to get all sub-attributes\n",
    "dict(zip(attributesNamesUnique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find products with an image + attribute -> build dataset from them\n",
    "attributesIdsUnique = list(set(attributesIds)) # (7362) List of ProductIds with at least one attribute and no ProductIds repetition\n",
    "#attributesIdsUniqueWithImage = [x for x in attributesIdsUnique if x in imageIds] # (7251) #check available image (not for 111) \n",
    "attributesIdsWithImage = [x for x in attributesIds if x in imageIds] # (13271)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find products with an image + no attribute + add their filename -> apply the algorithm on those products\n",
    "productsIdsNoAttribute = [x for x in productsIds if x not in attributesIdsUnique] #(5269)\n",
    "productsIdsNoAttributeWithImage = [x for x in productsIdsNoAttribute if x in imageIds] #(5185)\n",
    "productsIdsNoAttributeWithImageAddress = [ imageFullNames[ imageIds.index( x ) ] for x in productsIdsNoAttributeWithImage]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check all images are of the same size (255, 340) (yes)\n",
    "from PIL import Image\n",
    "tmp = []\n",
    "for i in range(len(attributesIdsUniqueImage)): \n",
    "    image = Image.open('images/' + imageFullNames[ imageIds.index( myProductId ) ] )\n",
    "    tmp.append(image.size)\n",
    "Counter(tmp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "STATS\n",
    "# 24 AttributeName \n",
    "# 92 AttributeValueName \n",
    "# (255, 340) size images\n",
    "# 7362 attributesIdsUnique\n",
    "# 7251 attributesIdsUniqueWithImage (train & test set : 7251 images)\n",
    "# 5185 productsIdsNoAttributeWithImage (application set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to build the dataset -> For each of the 24 attributes, list all ProductIds associated & possessing an image\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "dico = defaultdict(list) # dico: key is an attribute, value is a list of ProductId with this attribute & an image\n",
    "dicoAddress = defaultdict(list) #same but with image file names instead of just ProductId\n",
    "\n",
    "for (index, myProductId) in enumerate(attributesIds):\n",
    "    if myProductId in attributesIdsWithImage: \n",
    "        key = attributesNames[index]\n",
    "        dico[key].append(myProductId)\n",
    "        filename = imageFullNames[ imageIds.index( myProductId ) ]\n",
    "        dicoAddress[key].append(filename)\n",
    "    \n",
    "#ctr = sum(map(len, dico.values())); print(ctr) #used to count number of items in dico (13271)\n",
    "#length_dico = {key: len(value) for key, value in dico.items()}; print(length_dict) #create another dictionary containing length of lists of values\n",
    "\n",
    "dicoSmall = defaultdict(list) # Unbalanced training issue and high training time so take only first 10 images of each 24 classes.\n",
    "for key in dicoAddress:\n",
    "    tmp = dicoAddress[key]\n",
    "    dicoSmall[key] = tmp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicoSmallTrain = defaultdict(list) # split train:test 7:3\n",
    "dicoSmallTest = defaultdict(list)\n",
    "for key in  dicoSmall:\n",
    "    tmp =  dicoSmall[key]\n",
    "    dicoSmallTrain[key] = (tmp[:7])\n",
    "    dicoSmallTest[key] = (tmp[7:10])\n",
    "#print(dicoSmall['Denim Fit']);print(dicoSmallTrain['Denim Fit']);print(dicoSmallTest['Denim Fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [index for (index, x) in enumerate(attributesNames) if x == 'Sleeve Length'] # (3056) Get indices of products with Sleeve length attibute\n",
    "tmp = [attributesIds[x] for x in indices] #Get ProductId of those indices\n",
    "indices = [ indices[index] for (index,x) in enumerate(tmp) if x in imageIds ] # (3009) Remove indices (products) with no image available\n",
    "a = attributes[indices,0] #ProductIds\n",
    "b = attributes[indices,2] #sub-attributes\n",
    "c =  np.asarray( [ imageFullNames[ imageIds.index( myProductId ) ] for myProductId in a] ) #image filenames\n",
    "dataset = np.column_stack((a,b, c)) #Create a numpy array with ProductId | sub-attribute (label) | image filename\n",
    "classesList = np.unique(dataset[:,1]) # (7) number of sub-attributes \n",
    "print(classesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for subattribute in classesList:\n",
    "    directory = 'data/train/' + subattribute\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    directory = 'data/validation/' + subattribute\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "#problem with 3/4 sleeves, tell the engineering team -> changed to 3_4\n",
    "\n",
    "from shutil import copyfile\n",
    "for x in dataset:\n",
    "    src = 'images/' + x[2]\n",
    "    dst = 'data/train/' + x[1] + '/' + x[2]\n",
    "    if not os.path.exists(dst):\n",
    "        copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B - Run the algorithm on the datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Import image -> Grayscale -> Resize\n",
    "2. Train on 4 sub-attributes from 1 attributes -> Simple CNN -> Tune dropout + layers number\n",
    "3. Try Multi-label classification with the Keras link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(340, 255, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pre-processing, augmentation, dimensionality reduction\n",
    "\n",
    "batch_size = 16\n",
    "target_size = (340, 255) #can reduce dimension here\n",
    "color_mode = 'rgb' #can reduce dimension here\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing: only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=target_size,  # all images will be resized to target_size\n",
    "        batch_size = batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode=color_mode)  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        color_mode=color_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make the above work by preparing datasets in right directory + expanding to 7 classes + copying full code available on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
